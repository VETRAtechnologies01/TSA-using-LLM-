{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lj1rRV5zlL-",
        "outputId": "73eebf54-fbb8-47cc-9456-16c51f2520b5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Vc72woFzrl_",
        "outputId": "59f069a2-9308-402d-d0e2-01c6b41324db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.4.26)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.20.1)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.86.0\n",
            "    Uninstalling openai-1.86.0:\n",
            "      Successfully uninstalled openai-1.86.0\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCGfFVnNzxOm",
        "outputId": "3581933f-d142-439f-dd42-a414e323d7db"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.65)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.5)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.20.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btgWKJK5z2Uw",
        "outputId": "8843da10-38dd-491c-e754-9602c0317932"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.65)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.5)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.14.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai langchain langchain-openai python-dotenv pandas tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aH7o-kjD0Cb2",
        "outputId": "c93415fa-5ce7-4869-8df8-5ba16c1b8134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai) (2.32.3)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai) (3.11.15)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.65)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.5)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting openai\n",
            "  Using cached openai-1.86.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.20.0)\n",
            "Using cached openai-1.86.0-py3-none-any.whl (730 kB)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 0.28.0\n",
            "    Uninstalling openai-0.28.0:\n",
            "      Successfully uninstalled openai-0.28.0\n",
            "Successfully installed openai-1.86.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = \"sk-xxx\"  # Replace with your key\n"
      ],
      "metadata": {
        "id": "HqK9lQ-s0Ij9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paECXS9Awqbn",
        "outputId": "49dfc34a-d073-4259-cf79-d8a0b588e32a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deepseek in /usr/local/lib/python3.11/dist-packages (1.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from deepseek) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->deepseek) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->deepseek) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->deepseek) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->deepseek) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "pip install deepseek"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3NTzCru50SsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "import openai\n",
        "from tqdm import tqdm\n",
        "import zipfile\n",
        "\n",
        "# --- Load Keys ---\n",
        "load_dotenv()\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "api_key = openai.api_key or \"sk-your-fallback-key\"  # Replace if needed\n",
        "print(\"‚úÖ Loaded OpenAI Key:\", bool(api_key))\n",
        "\n",
        "# ‚úÖ LangChain LLM (explicit API key)\n",
        "llm = ChatOpenAI(model=\"gpt-4\", temperature=0.5, openai_api_key=api_key)\n",
        "\n",
        "# --- WhatsApp Chat Extraction ---\n",
        "def extract_whatsapp_messages(zip_path):\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_path, '/content/whatsapp_chat_analysis.zip') as zip_ref:\n",
        "            file_list = zip_ref.namelist()\n",
        "            print(\"üîç Files in ZIP:\", file_list)\n",
        "            txt_files = [f for f in file_list if f.endswith('.txt')]\n",
        "            if not txt_files:\n",
        "                print(\"‚ùå No .txt file found in ZIP archive.\")\n",
        "                return []\n",
        "            chat_file = txt_files[0]\n",
        "            with zip_ref.open(chat_file) as f:\n",
        "                try:\n",
        "                    chat_data = f.read().decode('utf-8')\n",
        "                except UnicodeDecodeError:\n",
        "                    chat_data = f.read().decode('latin1')\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ùå ZIP file not found: {zip_path}\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå Failed to extract chat:\", e)\n",
        "        return []\n",
        "\n",
        "    pattern = re.compile(r'^\\d{1,2}/\\d{1,2}/\\d{2,4}, \\d{1,2}:\\d{2} [APMapm]{2} - ([^:]+): (.+)$')\n",
        "    messages = []\n",
        "    for line in chat_data.split(\"\\n\"):\n",
        "        match = pattern.match(line)\n",
        "        if match:\n",
        "            sender, msg = match.groups()\n",
        "            if msg.strip() and \"media omitted\" not in msg.lower():\n",
        "                messages.append(f\"{sender}: {msg}\")\n",
        "    return messages\n",
        "\n",
        "\n",
        "# --- WhatsApp Chat Analysis ---\n",
        "def analyze_chat(messages, n=50):\n",
        "    recent = \"\\n\".join(messages[-n:])\n",
        "    prompt_template = \"\"\"\n",
        "You are a futuristic AI therapist from 2030.\n",
        "\n",
        "Analyze these WhatsApp messages:\n",
        "- Emotional tone (stress, joy, anxiety)\n",
        "- Mental clarity & decision style\n",
        "- Mindset type: proactive, reactive, balanced\n",
        "\n",
        "Recommend:\n",
        "- 3 apps/habits to avoid\n",
        "- 3 uplifting movies and songs\n",
        "- 3 good daily mental health habits\n",
        "\n",
        "Output ONLY in JSON format as:\n",
        "{\"emotional_tone\": \"...\", \"clarity\": \"...\", \"mindset\": \"...\", \"avoid\": [...], \"recommend\": {\"movies\": [...], \"songs\": [...]}, \"habits\": [...] }\n",
        "\n",
        "Chat:\n",
        "{chat}\n",
        "\"\"\"\n",
        "    prompt = PromptTemplate(input_variables=[\"chat\"], template=prompt_template)\n",
        "    formatted_prompt = prompt.format(chat=recent)\n",
        "    response = llm.invoke(formatted_prompt)\n",
        "\n",
        "    try:\n",
        "        return json.loads(response.content)\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"‚ö†Ô∏è JSON parsing failed in chat analysis. Raw output:\\n\", response.content)\n",
        "        return response.content\n",
        "\n",
        "# --- Screen Time Analysis ---\n",
        "def load_screen_time(csv_path):\n",
        "    return pd.read_csv(csv_path)\n",
        "\n",
        "def analyze_screen_time(df):\n",
        "    readable = df.to_string(index=False)\n",
        "    prompt_template = \"\"\"\n",
        "You are a digital wellness AI.\n",
        "\n",
        "Analyze this screen time data:\n",
        "- Focus vs distraction\n",
        "- Burnout, overuse, addiction\n",
        "- Decision fatigue signs\n",
        "\n",
        "Recommend:\n",
        "- Mental clarity (0-100)\n",
        "- Avoid apps\n",
        "- 3 inspiring movies and calming songs\n",
        "- 3 digital detox habits\n",
        "\n",
        "Output ONLY in JSON format as:\n",
        "{\"clarity_score\": 0-100, \"fatigue\": \"...\", \"avoid_apps\": [...], \"recommend\": {\"movies\": [...], \"songs\": [...]}, \"habits\": [...] }\n",
        "\n",
        "Screen Time Data:\n",
        "{data}\n",
        "\"\"\"\n",
        "    prompt = PromptTemplate(input_variables=[\"data\"], template=prompt_template)\n",
        "    formatted_prompt = prompt.format(data=readable)\n",
        "    response = llm.invoke(formatted_prompt)\n",
        "\n",
        "    try:\n",
        "        json_data = json.loads(response.content)\n",
        "        return validate_screen_time_json(json_data)\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"‚ö†Ô∏è JSON parsing failed in screen time analysis. Raw output:\\n\", response.content)\n",
        "        return response.content\n",
        "\n",
        "# Validation function for clarity_score\n",
        "def validate_screen_time_json(data):\n",
        "    if not isinstance(data, dict):\n",
        "        print(\"‚ö†Ô∏è Screen time data not a dict, returning None\")\n",
        "        return None\n",
        "    if \"clarity_score\" not in data:\n",
        "        print(\"‚ö†Ô∏è 'clarity_score' missing, setting default 50\")\n",
        "        data[\"clarity_score\"] = 50\n",
        "    else:\n",
        "        try:\n",
        "            val = int(data[\"clarity_score\"])\n",
        "            data[\"clarity_score\"] = max(0, min(100, val))\n",
        "        except Exception:\n",
        "            print(\"‚ö†Ô∏è 'clarity_score' invalid, setting default 50\")\n",
        "            data[\"clarity_score\"] = 50\n",
        "    return data\n",
        "\n",
        "# --- Twitter Sentiment Analysis ---\n",
        "def analyze_tweets(df):\n",
        "    print(\"üîç Columns in CSV:\", df.columns.tolist())\n",
        "    tweet_col = None\n",
        "    for col in df.columns:\n",
        "        if col.strip().lower() in [\"tweet\", \"text\", \"message\", \"content\"]:\n",
        "            tweet_col = col\n",
        "            break\n",
        "    if not tweet_col:\n",
        "        string_cols = df.select_dtypes(include='object')\n",
        "        tweet_col = string_cols.apply(lambda c: c.str.len().mean()).idxmax()\n",
        "        print(f\"‚úÖ Auto-selected tweet column: '{tweet_col}'\")\n",
        "\n",
        "    def analyze_sentiment_llm(tweet):\n",
        "        prompt = f\"\"\"\n",
        "You are a sentiment expert. Classify the tweet as one word: Positive, Negative, or Neutral.\n",
        "\n",
        "Tweet: \"{tweet}\"\n",
        "Sentiment:\"\"\"\n",
        "        try:\n",
        "            res = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0.0\n",
        "            )\n",
        "            return res['choices'][0]['message']['content'].strip()\n",
        "        except Exception as e:\n",
        "            print(\"‚ö†Ô∏è Error analyzing tweet:\", e)\n",
        "            return \"Error\"\n",
        "\n",
        "    tqdm.pandas()\n",
        "    df[\"sentiment\"] = df[tweet_col].progress_apply(analyze_sentiment_llm)\n",
        "    return df\n",
        "\n",
        "# --- Final Report Synthesis ---\n",
        "def synthesize_report(chat_json, screen_json, sentiment_df):\n",
        "    sentiment_counts = sentiment_df[\"sentiment\"].value_counts().to_dict()\n",
        "    sentiment_summary = f\"Sentiment counts: {sentiment_counts}\"\n",
        "\n",
        "    prompt_template = \"\"\"\n",
        "You are a NeuroAI fusion advisor from the future.\n",
        "\n",
        "Combine these:\n",
        "1. WhatsApp analysis:\n",
        "{chat_json}\n",
        "\n",
        "2. Screen time report:\n",
        "{screen_json}\n",
        "\n",
        "3. Twitter sentiment:\n",
        "{sentiments}\n",
        "\n",
        "Summarize teen mental health:\n",
        "- Mood and stress pattern\n",
        "- Top 3 issues\n",
        "- Mindfulness movie/song list\n",
        "- Futuristic habit suggestions\n",
        "\n",
        "Respond warmly and clearly.\n",
        "\"\"\"\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"chat_json\", \"screen_json\", \"sentiments\"],\n",
        "        template=prompt_template\n",
        "    )\n",
        "    formatted_prompt = prompt.format(\n",
        "        chat_json=json.dumps(chat_json, indent=2) if isinstance(chat_json, dict) else str(chat_json),\n",
        "        screen_json=json.dumps(screen_json, indent=2) if isinstance(screen_json, dict) else str(screen_json),\n",
        "        sentiments=sentiment_summary\n",
        "    )\n",
        "    response = llm.invoke(formatted_prompt)\n",
        "    return response.content\n",
        "\n",
        "# --- MAIN PIPELINE ---\n",
        "if __name__ == \"__main__\":\n",
        "    whatsapp_file = \"whatsapp_chat_analysis.zip\"\n",
        "    screen_time_file = \"/content/screentime_analysis.csv\"\n",
        "    twitter_file = \"teen_tweets.csv\"\n",
        "\n",
        "    try:\n",
        "        # 1. WhatsApp\n",
        "        chat_msgs = extract_whatsapp_messages(whatsapp_file)\n",
        "        chat_result = analyze_chat(chat_msgs) if chat_msgs else \"No usable messages.\"\n",
        "\n",
        "        # 2. Screen Time\n",
        "        df_screen = load_screen_time(screen_time_file)\n",
        "        screen_result = analyze_screen_time(df_screen)\n",
        "\n",
        "        # 3. Twitter Sentiment\n",
        "        df_tweets = pd.read_csv(twitter_file)\n",
        "        sentiment_df = analyze_tweets(df_tweets)\n",
        "\n",
        "        # 4. Final Mental Health Report\n",
        "        final_report = synthesize_report(chat_result, screen_result, sentiment_df)\n",
        "        print(\"\\nüß† Final Mental Health Summary:\\n\", final_report)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå Pipeline failed:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkBdzmMsryKy",
        "outputId": "4a7800e6-0171-48d4-8899-fb63fb11d8d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loaded OpenAI Key: True\n",
            "‚ùå Failed to extract chat: ZipFile requires mode 'r', 'w', 'x', or 'a'\n",
            "‚ùå Pipeline failed: '\"clarity_score\"'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SCxASsLr0iv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema import HumanMessage\n",
        "import openai\n",
        "from tqdm import tqdm\n",
        "import zipfile\n",
        "import time\n",
        "\n",
        "# Load environment variables and OpenAI key\n",
        "load_dotenv()\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "api_key = openai.api_key or \"sk-your-fallback-key\"\n",
        "print(\"‚úÖ Loaded OpenAI Key:\", bool(api_key))\n",
        "\n",
        "# Initialize LangChain LLM with explicit API key\n",
        "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.5, openai_api_key=api_key)\n",
        "\n",
        "# --- WhatsApp Chat Extraction ---\n",
        "def extract_whatsapp_messages(zip_path):\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            file_list = zip_ref.namelist()\n",
        "            print(\"üîç Files in ZIP:\", file_list)\n",
        "            txt_files = [f for f in file_list if f.endswith('.txt')]\n",
        "            if not txt_files:\n",
        "                print(\"/content/whatsapp_chat_analysis.zip.\")\n",
        "                return []\n",
        "            chat_file = txt_files[0]\n",
        "            with zip_ref.open(chat_file) as f:\n",
        "                try:\n",
        "                    chat_data = f.read().decode('utf-8')\n",
        "                except UnicodeDecodeError:\n",
        "                    chat_data = f.read().decode('latin1')\n",
        "    except FileNotFoundError:\n",
        "        print(f\"‚ùå ZIP file not found: {zip_path}\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå Failed to extract chat:\", e)\n",
        "        return []\n",
        "\n",
        "    # Join multiline messages: lines NOT starting with date pattern belong to previous line\n",
        "    lines = chat_data.split('\\n')\n",
        "    merged_lines = []\n",
        "    date_pattern = re.compile(r'^\\d{1,2}/\\d{1,2}/\\d{2,4}, \\d{1,2}:\\d{2} [APMapm]{2} - ')\n",
        "    buffer = \"\"\n",
        "    for line in lines:\n",
        "        if date_pattern.match(line):\n",
        "            if buffer:\n",
        "                merged_lines.append(buffer)\n",
        "            buffer = line\n",
        "        else:\n",
        "            buffer += \" \" + line.strip()\n",
        "    if buffer:\n",
        "        merged_lines.append(buffer)\n",
        "\n",
        "    pattern = re.compile(r'^\\d{1,2}/\\d{1,2}/\\d{2,4}, \\d{1,2}:\\d{2} [APMapm]{2} - ([^:]+): (.+)$')\n",
        "    messages = []\n",
        "    for line in merged_lines:\n",
        "        match = pattern.match(line)\n",
        "        if match:\n",
        "            sender, msg = match.groups()\n",
        "            if msg.strip() and \"media omitted\" not in msg.lower():\n",
        "                messages.append(f\"{sender}: {msg}\")\n",
        "    print(f\"‚úÖ Extracted {len(messages)} messages from chat\")\n",
        "    return messages\n",
        "\n",
        "# --- WhatsApp Chat Analysis ---\n",
        "def analyze_chat(messages, n=50):\n",
        "    recent = \"\\n\".join(messages[-n:])\n",
        "    prompt_template_str = \"\"\"\n",
        "You are a futuristic AI therapist from 2030.\n",
        "\n",
        "Analyze these WhatsApp messages:\n",
        "- Emotional tone (stress, joy, anxiety)\n",
        "- Mental clarity & decision style\n",
        "- Mindset type: proactive, reactive, balanced\n",
        "\n",
        "Recommend:\n",
        "- 3 apps/habits to avoid\n",
        "- 3 uplifting movies and songs\n",
        "- 3 good daily mental health habits\n",
        "\n",
        "Output ONLY in JSON format as:\n",
        "{\"emotional_tone\": \"...\", \"clarity\": \"...\", \"mindset\": \"...\", \"avoid\": [...], \"recommend\": {\"movies\": [...], \"songs\": [...]}, \"habits\": [...] }\n",
        "\n",
        "Chat:\n",
        "{chat}\n",
        "\"\"\"\n",
        "    prompt = PromptTemplate(input_variables=[\"chat\"], template=prompt_template_str)\n",
        "    formatted_prompt = prompt.format(chat=recent)\n",
        "\n",
        "    response = llm([HumanMessage(content=formatted_prompt)])\n",
        "    text = response[0].content if isinstance(response, list) else getattr(response, \"content\", str(response))\n",
        "\n",
        "    try:\n",
        "        return json.loads(text)\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"‚ö†Ô∏è JSON parsing failed in chat analysis. Raw output:\\n\", text)\n",
        "        return text\n",
        "\n",
        "# --- Screen Time Analysis ---\n",
        "def load_screen_time(csv_path):\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path)\n",
        "        print(f\"‚úÖ Loaded screen time data: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to load screen time CSV: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def analyze_screen_time(df):\n",
        "    readable = df.to_string(index=False)\n",
        "    prompt_template_str = \"\"\"\n",
        "You are a digital wellness AI.\n",
        "\n",
        "Analyze this screen time data:\n",
        "- Focus vs distraction\n",
        "- Burnout, overuse, addiction\n",
        "- Decision fatigue signs\n",
        "\n",
        "Recommend:\n",
        "- Mental clarity (0-100)\n",
        "- Avoid apps\n",
        "- 3 inspiring movies and calming songs\n",
        "- 3 digital detox habits\n",
        "\n",
        "Output ONLY in JSON format as:\n",
        "{\"clarity_score\": 0, \"fatigue\": \"...\", \"avoid_apps\": [...], \"recommend\": {\"movies\": [...], \"songs\": [...]}, \"habits\": [...] }\n",
        "\n",
        "Screen Time Data:\n",
        "{data}\n",
        "\"\"\"\n",
        "    prompt = PromptTemplate(input_variables=[\"data\"], template=prompt_template_str)\n",
        "    formatted_prompt = prompt.format(data=readable)\n",
        "\n",
        "    response = llm([HumanMessage(content=formatted_prompt)])\n",
        "    text = response[0].content if isinstance(response, list) else getattr(response, \"content\", str(response))\n",
        "\n",
        "    def validate_screen_time_json(data):\n",
        "      if not isinstance(data, dict):\n",
        "        print(\"‚ö†Ô∏è Screen time data not a dict, returning None\")\n",
        "        return None\n",
        "    df[\"clarity_score\"]\n",
        "    results.get(\"clarity_score\", 50)\n",
        "\n",
        "    if \"clarity_score\" in df.columns:\n",
        "        clarity = df[\"clarity_score\"]\n",
        "    else:\n",
        "        print(\"Column 'clarity_score' not found.\")\n",
        "        clarity = None  # or some default value\n",
        "        try:\n",
        "            val = int(data[\"clarity_score\"])\n",
        "            data[\"clarity_score\"] = max(0, min(100, val))\n",
        "        except Exception:\n",
        "            print(\"‚ö†Ô∏è 'clarity_score' invalid type, setting default 50\")\n",
        "            data[\"clarity_score\"] = 50\n",
        "\n",
        "    # Optional: Check other keys if necessary and fill defaults or clean\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "# --- Twitter Sentiment Analysis ---\n",
        "def analyze_tweets(df):\n",
        "    print(\"üîç Columns in CSV:\", df.columns.tolist())\n",
        "    tweet_col = None\n",
        "    for col in df.columns:\n",
        "        if col.strip().lower() in [\"tweet\", \"text\", \"message\", \"content\"]:\n",
        "            tweet_col = col\n",
        "            break\n",
        "    if not tweet_col:\n",
        "        string_cols = df.select_dtypes(include='object')\n",
        "        tweet_col = string_cols.apply(lambda c: c.str.len().mean()).idxmax()\n",
        "        print(f\"‚úÖ Auto-selected tweet column: '{tweet_col}'\")\n",
        "\n",
        "    def analyze_sentiment_llm(tweet):\n",
        "        prompt = f\"\"\"\n",
        "You are a sentiment expert. Classify the tweet as one word: Positive, Negative, or Neutral.\n",
        "\n",
        "Tweet: \"{tweet}\"\n",
        "Sentiment:\"\"\"\n",
        "        try:\n",
        "            res = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0.0\n",
        "            )\n",
        "            sentiment = res['choices'][0]['message']['content'].strip()\n",
        "            # Normalize output\n",
        "            if sentiment.lower() not in [\"positive\", \"negative\", \"neutral\"]:\n",
        "                return \"Neutral\"\n",
        "            return sentiment\n",
        "        except Exception as e:\n",
        "            print(\"‚ö†Ô∏è Error analyzing tweet:\", e)\n",
        "            return \"Error\"\n",
        "\n",
        "    tqdm.pandas()\n",
        "    df[\"sentiment\"] = df[tweet_col].progress_apply(analyze_sentiment_llm)\n",
        "    return df\n",
        "\n",
        "# --- Final Report Synthesis ---\n",
        "def synthesize_report(chat_json, screen_json, sentiment_df):\n",
        "    sentiment_counts = sentiment_df[\"sentiment\"].value_counts().to_dict()\n",
        "    sentiment_summary = f\"Sentiment counts: {sentiment_counts}\"\n",
        "\n",
        "    prompt_template_str = \"\"\"\n",
        "You are a NeuroAI fusion advisor from the future.\n",
        "\n",
        "Combine these:\n",
        "1. WhatsApp analysis:\n",
        "{chat_json}\n",
        "\n",
        "2. Screen time report:\n",
        "{screen_json}\n",
        "\n",
        "3. Twitter sentiment:\n",
        "{sentiments}\n",
        "\n",
        "Summarize teen mental health:\n",
        "- Mood and stress pattern\n",
        "- Top 3 issues\n",
        "- Mindfulness movie/song list\n",
        "- Futuristic habit suggestions\n",
        "\n",
        "Respond warmly and clearly.\n",
        "\"\"\"\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"chat_json\", \"screen_json\", \"sentiments\"],\n",
        "        template=prompt_template_str\n",
        "    )\n",
        "    formatted_prompt = prompt.format(\n",
        "        chat_json=json.dumps(chat_json, indent=2) if isinstance(chat_json, dict) else str(chat_json),\n",
        "        screen_json=json.dumps(screen_json, indent=2) if isinstance(screen_json, dict) else str(screen_json),\n",
        "        sentiments=sentiment_summary\n",
        "    )\n",
        "\n",
        "    response = llm([HumanMessage(content=formatted_prompt)])\n",
        "    text = response[0].content if isinstance(response, list) else getattr(response, \"content\", str(response))\n",
        "    return text\n",
        "\n",
        "# --- MAIN PIPELINE ---\n",
        "if __name__ == \"__main__\":\n",
        "    whatsapp_file = \"whatsapp_chat_analysis.zip\"\n",
        "    screen_time_file = \"screentime_analysis.csv\"\n",
        "    twitter_file = \"teen_tweets.csv\"\n",
        "\n",
        "    try:\n",
        "        # 1. WhatsApp\n",
        "        chat_msgs = extract_whatsapp_messages(whatsapp_file)\n",
        "        chat_result = analyze_chat(chat_msgs) if chat_msgs else \"No usable messages.\"\n",
        "\n",
        "        # 2. Screen Time\n",
        "        df_screen = load_screen_time(screen_time_file)\n",
        "        screen_result = analyze_screen_time(df_screen) if not df_screen.empty else \"No screen time data.\"\n",
        "\n",
        "        # 3. Twitter Sentiment\n",
        "        df_tweets = pd.read_csv(twitter_file)\n",
        "        sentiment_df = analyze_tweets(df_tweets)\n",
        "\n",
        "        # 4. Final Mental Health Report\n",
        "        final_report = synthesize_report(chat_result, screen_result, sentiment_df)\n",
        "        print(\"\\nüß† Final Mental Health Summary:\\n\", final_report)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\" Pipeline :\", e)\n",
        "\n",
        "    import json\n",
        "\n",
        "# --- INPUT JSON ---\n",
        "data = '''\n",
        "{\n",
        "  \"mood\": \"Stressed and anxious with periods of joy\",\n",
        "  \"top_issues\": [\"Overuse of social media\", \"Sleep deprivation\", \"Lack of mental clarity\"],\n",
        "  \"recommended_movies\": [\"Inside Out\", \"The Pursuit of Happyness\", \"Soul\"],\n",
        "  \"recommended_songs\": [\"Weightless - Marconi Union\", \"Lovely Day - Bill Withers\", \"Here Comes the Sun - The Beatles\"],\n",
        "  \"habits\": [\"Daily journaling\", \"30-minute screen-free walk\", \"Night-time digital detox routine\"]\n",
        "}\n",
        "'''\n",
        "\n",
        "# --- LOAD JSON INTO PYTHON DICTIONARY ---\n",
        "analysis = json.loads(data)\n",
        "\n",
        "# --- PRINT IN A CLEAN FORMAT ---\n",
        "print(\"\\nüß† Mood Summary:\")\n",
        "print(f\"  - Mood: {analysis['mood']}\")\n",
        "\n",
        "print(\"\\nüö© Top Issues Detected:\")\n",
        "for issue in analysis['top_issues']:\n",
        "    print(f\"  - {issue}\")\n",
        "\n",
        "print(\"\\nüé¨ Recommended Movies:\")\n",
        "for movie in analysis['recommended_movies']:\n",
        "    print(f\"  - {movie}\")\n",
        "\n",
        "print(\"\\nüéµ Recommended Songs:\")\n",
        "for song in analysis['recommended_songs']:\n",
        "    print(f\"  - {song}\")\n",
        "\n",
        "print(\"\\nüåø Suggested Mental Health Habits:\")\n",
        "for habit in analysis['habits']:\n",
        "    print(f\"  - {habit}\")\n",
        "\n",
        "\n",
        "def analyze_screen_time(df):\n",
        "    readable = df.to_string(index=False)\n",
        "\n",
        "    prompt_template_str = \"\"\"\n",
        "You are a digital wellness AI.\n",
        "\n",
        "Analyze this screen time data:\n",
        "- Focus vs distraction\n",
        "- Burnout, overuse, addiction\n",
        "- Decision fatigue signs\n",
        "\n",
        "Recommend:\n",
        "- Mental clarity (0-100)\n",
        "- Avoid apps\n",
        "- 3 inspiring movies and calming songs\n",
        "- 3 digital detox habits\n",
        "\n",
        "Output ONLY in JSON format as:\n",
        "{\"clarity_score\": 0, \"fatigue\": \"...\", \"avoid_apps\": [...], \"recommend\": {\"movies\": [...], \"songs\": [...]}, \"habits\": [...] }\n",
        "\n",
        "Screen Time Data:\n",
        "{data}\n",
        "\"\"\"\n",
        "    prompt = PromptTemplate(input_variables=[\"data\"], template=prompt_template_str)\n",
        "    formatted_prompt = prompt.format(data=readable)\n",
        "\n",
        "    response = llm([HumanMessage(content=formatted_prompt)])\n",
        "    text = response[0].content if isinstance(response, list) else getattr(response, \"content\", str(response))\n",
        "\n",
        "    try:\n",
        "        data = json.loads(text)\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"‚ö†Ô∏è JSON parsing failed in screen time analysis. Raw output:\\n\", text)\n",
        "        return {\"clarity_score\": 50, \"fatigue\": \"Unknown\", \"avoid_apps\": [], \"recommend\": {\"movies\": [], \"songs\": []}, \"habits\": []}\n",
        "\n",
        "    # ‚úÖ Validation & fallback handling\n",
        "    if not isinstance(data, dict):\n",
        "        print(\"‚ö†Ô∏è Screen time JSON result is not a dictionary.\")\n",
        "        return {\"clarity_score\": 50, \"fatigue\": \"Unknown\", \"avoid_apps\": [], \"recommend\": {\"movies\": [], \"songs\": []}, \"habits\": []}\n",
        "\n",
        "    # Clamp clarity score between 0‚Äì100\n",
        "    try:\n",
        "        val = int(data.get(\"clarity_score\", 50))\n",
        "        data[\"clarity_score\"] = max(0, min(100, val))\n",
        "    except Exception:\n",
        "        print(\"‚ö†Ô∏è Invalid clarity_score, setting default 50\")\n",
        "        data[\"clarity_score\"] = 50\n",
        "\n",
        "    return data\n",
        "print(f\"üß† Mood: {analysis['mood']} | üö© Issues: {', '.join(analysis['top_issues'])} | üé¨ Movies: {', '.join(analysis['recommended_movies'])} | üéµ Songs: {', '.join(analysis['recommended_songs'])} | üåø Habits: {', '.join(analysis['habits'])}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmLnYSLrxSH_",
        "outputId": "468ada12-1022-4700-93cd-56d1a5e9d68d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loaded OpenAI Key: True\n",
            "üîç Files in ZIP: ['whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/1.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/10.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/11.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/12.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/13.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/14.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/15.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/16.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/17.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/18.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/19.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/2.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/20.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/21.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/3.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/4.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/5.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/6.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/7.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/8.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/9.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/A+sw.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/Dataset.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/L+sw.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/both+sw.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/both.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/sentiment_NLTK_neg.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/sentiment_NLTK_pos.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/sentiment_spanish_neg.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/sentiment_spanish_pos.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/sentiment_text_blob_down.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/sentiment_text_blob_pos.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/translated.png', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/README.md', 'whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Whatsapp_Analysis.ipynb']\n",
            "/content/whatsapp_chat_analysis.zip.\n",
            "‚úÖ Loaded screen time data: 200 rows, 5 columns\n",
            " Pipeline : '\"clarity_score\"'\n",
            "\n",
            "üß† Mood Summary:\n",
            "  - Mood: Stressed and anxious with periods of joy\n",
            "\n",
            "üö© Top Issues Detected:\n",
            "  - Overuse of social media\n",
            "  - Sleep deprivation\n",
            "  - Lack of mental clarity\n",
            "\n",
            "üé¨ Recommended Movies:\n",
            "  - Inside Out\n",
            "  - The Pursuit of Happyness\n",
            "  - Soul\n",
            "\n",
            "üéµ Recommended Songs:\n",
            "  - Weightless - Marconi Union\n",
            "  - Lovely Day - Bill Withers\n",
            "  - Here Comes the Sun - The Beatles\n",
            "\n",
            "üåø Suggested Mental Health Habits:\n",
            "  - Daily journaling\n",
            "  - 30-minute screen-free walk\n",
            "  - Night-time digital detox routine\n",
            "üß† Mood: Stressed and anxious with periods of joy | üö© Issues: Overuse of social media, Sleep deprivation, Lack of mental clarity | üé¨ Movies: Inside Out, The Pursuit of Happyness, Soul | üéµ Songs: Weightless - Marconi Union, Lovely Day - Bill Withers, Here Comes the Sun - The Beatles | üåø Habits: Daily journaling, 30-minute screen-free walk, Night-time digital detox routine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-2584495290>:21: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.5, openai_api_key=api_key)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from dotenv import load_dotenv\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema import HumanMessage\n",
        "import openai\n",
        "from tqdm import tqdm\n",
        "import zipfile\n",
        "import requests\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Install required packages\n",
        "!pip install python-dotenv langchain openai pandas tqdm requests\n",
        "\n",
        "# --- Setup for Google Colab ---\n",
        "# Upload your files\n",
        "print(\"Please upload your files:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the uploaded file names\n",
        "uploaded_files = list(uploaded.keys())\n",
        "print(\"Uploaded files:\", uploaded_files)\n",
        "\n",
        "# Set up environment variables\n",
        "os.environ[\"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\"] = \"\"  # You'll set this below\n",
        "os.environ[\"DEEPSEEK_API_KEY\"] = \"\"  # You'll set this below\n",
        "\n",
        "# --- API Key Setup ---\n",
        "print(\"\\nüîë API Key Setup\")\n",
        "print(\"1. Get your OpenAI API key from: https://platform.openai.com/api-keys\")\n",
        "print(\"2. Get your DeepSeek API key from their website (if using DeepSeek)\")\n",
        "\n",
        "OPENAI_API_KEY = input(\"Enter your OpenAI API key (or press Enter to skip): \").strip()\n",
        "DEEPSEEK_API_KEY = input(\"Enter your DeepSeek API key (or press Enter to skip): \").strip()\n",
        "\n",
        "if not OPENAI_API_KEY and not DEEPSEEK_API_KEY:\n",
        "    print(\"‚ùå Error: You need at least one API key to continue\")\n",
        "    exit()\n",
        "\n",
        "if OPENAI_API_KEY:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "if DEEPSEEK_API_KEY:\n",
        "    os.environ[\"DEEPSEEK_API_KEY\"] = DEEPSEEK_API_KEY\n",
        "\n",
        "# Initialize models\n",
        "llm_gpt = None\n",
        "if OPENAI_API_KEY:\n",
        "    try:\n",
        "        llm_gpt = ChatOpenAI(\n",
        "            model_name=\"gpt-3.5-turbo\",\n",
        "            temperature=0.5,\n",
        "            openai_api_key=OPENAI_API_KEY\n",
        "        )\n",
        "        print(\"‚úÖ OpenAI GPT initialized successfully\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to initialize OpenAI: {e}\")\n",
        "\n",
        "# --- DeepSeek Helper Functions ---\n",
        "def deepseek_completion(prompt, model=\"deepseek-chat\"):\n",
        "    if not DEEPSEEK_API_KEY:\n",
        "        return \"DeepSeek API key not available\"\n",
        "\n",
        "    headers = {\n",
        "        \"Authorization\": f\"Bearer {DEEPSEEK_API_KEY}\",\n",
        "        \"Content-Type\": \"application/json\"\n",
        "    }\n",
        "    payload = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "        \"temperature\": 0.5\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            \"https://api.deepseek.com/v1/chat/completions\",\n",
        "            headers=headers,\n",
        "            json=payload,\n",
        "            timeout=30\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå DeepSeek API error: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "# --- Model Selection Helper ---\n",
        "def get_llm_response(prompt, model=\"deepseek\"):\n",
        "    if model.lower() == \"gpt\" and llm_gpt:\n",
        "        try:\n",
        "            response = llm_gpt([HumanMessage(content=prompt)])\n",
        "            return response[0].content if isinstance(response, list) else str(response)\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå OpenAI error: {e}\")\n",
        "            return \"\"\n",
        "    elif model.lower() == \"deepseek\":\n",
        "        return deepseek_completion(prompt)\n",
        "    else:\n",
        "        return \"Invalid model selected\"\n",
        "\n",
        "# --- WhatsApp Chat Extraction ---\n",
        "def extract_whatsapp_messages(zip_path):\n",
        "    if not os.path.exists(zip_path):\n",
        "        print(f\"‚ùå WhatsApp file not found: {zip_path}\")\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            txt_files = [f for f in zip_ref.namelist() if f.endswith('.txt')]\n",
        "            if not txt_files:\n",
        "                return []\n",
        "            with zip_ref.open(txt_files[0]) as f:\n",
        "                try:\n",
        "                    chat_data = f.read().decode('utf-8')\n",
        "                except UnicodeDecodeError:\n",
        "                    chat_data = f.read().decode('latin1')\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå Error extracting chat:\", e)\n",
        "        return []\n",
        "\n",
        "    lines = chat_data.split('\\n')\n",
        "    merged_lines = []\n",
        "    date_pattern = re.compile(r'^\\d{1,2}/\\d{1,2}/\\d{2,4}, \\d{1,2}:\\d{2} [APMapm]{2} - ')\n",
        "    buffer = \"\"\n",
        "    for line in lines:\n",
        "        if date_pattern.match(line):\n",
        "            if buffer:\n",
        "                merged_lines.append(buffer)\n",
        "            buffer = line\n",
        "        else:\n",
        "            buffer += \" \" + line.strip()\n",
        "    if buffer:\n",
        "        merged_lines.append(buffer)\n",
        "\n",
        "    pattern = re.compile(r'^\\d{1,2}/\\d{1,2}/\\d{2,4}, \\d{1,2}:\\d{2} [APMapm]{2} - ([^:]+): (.+)$')\n",
        "    messages = [f\"{m.group(1)}: {m.group(2)}\" for m in map(pattern.match, merged_lines) if m and \"media omitted\" not in m.group(2).lower()]\n",
        "    return messages\n",
        "\n",
        "# --- WhatsApp Chat Analysis ---\n",
        "def analyze_chat(messages, n=50, model=\"deepseek\"):\n",
        "    if not messages:\n",
        "        return {\"error\": \"No messages to analyze\"}\n",
        "\n",
        "    recent = \"\\n\".join(messages[-n:])\n",
        "    prompt_template = \"\"\"\n",
        "You are a futuristic AI therapist from 2030.\n",
        "\n",
        "Analyze these WhatsApp messages:\n",
        "- Emotional tone (stress, joy, anxiety)\n",
        "- Mental clarity & decision style\n",
        "- Mindset type: proactive, reactive, balanced\n",
        "\n",
        "Recommend:\n",
        "- 3 apps/habits to avoid\n",
        "- 3 uplifting movies and songs\n",
        "- 3 good daily mental health habits\n",
        "\n",
        "Output ONLY in JSON format:\n",
        "{\"emotional_tone\": \"...\", \"clarity\": \"...\", \"mindset\": \"...\", \"avoid\": [...], \"recommend\": {\"movies\": [...], \"songs\": [...]}, \"habits\": [...]}\n",
        "\n",
        "Chat:\n",
        "{chat}\n",
        "\"\"\"\n",
        "    prompt = prompt_template.format(chat=recent)\n",
        "    response = get_llm_response(prompt, model)\n",
        "    try:\n",
        "        return json.loads(response)\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è Chat JSON parse error. Raw response:\\n\", response)\n",
        "        return {\"error\": \"Failed to parse analysis\"}\n",
        "\n",
        "# --- Screen Time Analysis ---\n",
        "def load_screen_time(csv_path):\n",
        "    if not os.path.exists(csv_path):\n",
        "        print(f\"‚ùå Screen time file not found: {csv_path}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    try:\n",
        "        return pd.read_csv(csv_path)\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to load screen time CSV: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def analyze_screen_time(df, model=\"deepseek\"):\n",
        "    if df.empty:\n",
        "        return {\"error\": \"No screen time data\"}\n",
        "\n",
        "    readable = df.to_string(index=False)\n",
        "    prompt_template = \"\"\"\n",
        "You are a digital wellness AI.\n",
        "\n",
        "Analyze this screen time data:\n",
        "- Focus vs distraction\n",
        "- Burnout, overuse, addiction\n",
        "- Decision fatigue signs\n",
        "\n",
        "Recommend:\n",
        "- Mental clarity (0-100)\n",
        "- Avoid apps\n",
        "- 3 inspiring movies and calming songs\n",
        "- 3 digital detox habits\n",
        "\n",
        "Output ONLY in JSON format:\n",
        "{\"clarity_score\": 0, \"fatigue\": \"...\", \"avoid_apps\": [...], \"recommend\": {\"movies\": [...], \"songs\": [...]}, \"habits\": [...]}\n",
        "\n",
        "Screen Time Data:\n",
        "{data}\n",
        "\"\"\"\n",
        "    prompt = prompt_template.format(data=readable)\n",
        "    response = get_llm_response(prompt, model)\n",
        "    try:\n",
        "        data = json.loads(response)\n",
        "        data[\"clarity_score\"] = max(0, min(100, int(data.get(\"clarity_score\", 50))))\n",
        "        return data\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è Screen time JSON parse error. Raw response:\\n\", response)\n",
        "        return {\"error\": \"Failed to parse analysis\"}\n",
        "\n",
        "# --- Twitter Sentiment Analysis ---\n",
        "def analyze_tweets(df, model=\"deepseek\"):\n",
        "    if df.empty:\n",
        "        print(\"‚ùå No tweet data available\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    tweet_col = next((col for col in df.columns if col.lower() in [\"tweet\", \"text\", \"message\", \"content\"]), None)\n",
        "    if not tweet_col:\n",
        "        tweet_col = df.select_dtypes(include='object').columns[0]\n",
        "\n",
        "    def analyze_sentiment(tweet):\n",
        "        prompt = f'Tweet: \"{tweet}\"\\nClassify as one word: Positive, Negative, or Neutral.'\n",
        "        response = get_llm_response(prompt, model)\n",
        "        sentiment = response.strip().capitalize()\n",
        "        return sentiment if sentiment in [\"Positive\", \"Negative\", \"Neutral\"] else \"Neutral\"\n",
        "\n",
        "    tqdm.pandas(desc=\"Analyzing tweets\")\n",
        "    df[\"sentiment\"] = df[tweet_col].progress_apply(analyze_sentiment)\n",
        "    return df\n",
        "\n",
        "# --- Final Report ---\n",
        "def synthesize_report(chat_json, screen_json, sentiment_df, model=\"deepseek\"):\n",
        "    if isinstance(chat_json, str) or \"error\" in chat_json:\n",
        "        chat_json = {\"error\": \"No chat analysis available\"}\n",
        "    if isinstance(screen_json, str) or \"error\" in screen_json:\n",
        "        screen_json = {\"error\": \"No screen time analysis available\"}\n",
        "    if sentiment_df.empty:\n",
        "        sentiment_summary = {\"error\": \"No sentiment analysis available\"}\n",
        "    else:\n",
        "        sentiment_summary = sentiment_df[\"sentiment\"].value_counts().to_dict()\n",
        "\n",
        "    prompt = \"\"\"\n",
        "You are a NeuroAI advisor. Create a comprehensive mental health report based on:\n",
        "\n",
        "1. WhatsApp Analysis:\n",
        "{chat_json}\n",
        "\n",
        "2. Screen Time Report:\n",
        "{screen_json}\n",
        "\n",
        "3. Twitter Sentiment:\n",
        "{sentiments}\n",
        "\n",
        "Include these sections:\n",
        "- Overall mood assessment\n",
        "- Top 3 concerns\n",
        "- Recommended media (movies/songs)\n",
        "- 3 personalized daily habits\n",
        "- Digital wellness suggestions\n",
        "\n",
        "Write in a compassionate, professional tone.\n",
        "\"\"\"\n",
        "    full_prompt = prompt.format(\n",
        "        chat_json=json.dumps(chat_json, indent=2),\n",
        "        screen_json=json.dumps(screen_json, indent=2),\n",
        "        sentiments=json.dumps(sentiment_summary, indent=2)\n",
        "    )\n",
        "    return get_llm_response(full_prompt, model)\n",
        "\n",
        "# --- MAIN PIPELINE ---\n",
        "def main():\n",
        "    # Input files configuration (use the names you uploaded)\n",
        "    input_files = {\n",
        "        \"whatsapp\": None,\n",
        "        \"screen_time\": None,\n",
        "        \"twitter\": None\n",
        "    }\n",
        "\n",
        "    # Match uploaded files to expected types\n",
        "    for filename in uploaded_files:\n",
        "        if 'whatsapp' in filename.lower() or filename.endswith('.zip'):\n",
        "            input_files[\"whatsapp\"] = filename\n",
        "        elif 'screen' in filename.lower() or filename.endswith('.csv'):\n",
        "            input_files[\"screen_time\"] = filename\n",
        "        elif 'tweet' in filename.lower() or filename.endswith('.csv'):\n",
        "            input_files[\"twitter\"] = filename\n",
        "\n",
        "    # Verify we found all required files\n",
        "    missing_files = [name for name, path in input_files.items() if path is None]\n",
        "    if missing_files:\n",
        "        print(f\"‚ùå Could not identify these required files: {', '.join(missing_files)}\")\n",
        "        print(\"Please ensure your uploaded files contain these keywords in their names:\")\n",
        "        print(\"- whatsapp (or .zip) for WhatsApp chat\")\n",
        "        print(\"- screen (or .csv) for screen time data\")\n",
        "        print(\"- tweet (or .csv) for Twitter data\")\n",
        "        return\n",
        "\n",
        "    # Check available models\n",
        "    available_models = []\n",
        "    if llm_gpt:\n",
        "        available_models.append(\"gpt\")\n",
        "    if DEEPSEEK_API_KEY:\n",
        "        available_models.append(\"deepseek\")\n",
        "\n",
        "    if not available_models:\n",
        "        print(\"‚ùå No available models. Please check your API keys.\")\n",
        "        return\n",
        "\n",
        "    # Model selection\n",
        "    print(f\"\\nAvailable models: {', '.join(available_models)}\")\n",
        "    model_choice = input(\"Choose model: \").strip().lower()\n",
        "    while model_choice not in available_models:\n",
        "        print(f\"Invalid choice. Please select from: {', '.join(available_models)}\")\n",
        "        model_choice = input(\"Choose model: \").strip().lower()\n",
        "\n",
        "    try:\n",
        "        print(\"\\nüîç Starting analysis...\")\n",
        "\n",
        "        # WhatsApp analysis\n",
        "        print(\"- Analyzing WhatsApp messages...\")\n",
        "        whatsapp_messages = extract_whatsapp_messages(input_files[\"whatsapp\"])\n",
        "        whatsapp_analysis = analyze_chat(whatsapp_messages, model=model_choice)\n",
        "\n",
        "        # Screen time analysis\n",
        "        print(\"- Analyzing screen time data...\")\n",
        "        screen_df = load_screen_time(input_files[\"screen_time\"])\n",
        "        screen_analysis = analyze_screen_time(screen_df, model=model_choice)\n",
        "\n",
        "        # Twitter analysis\n",
        "        print(\"- Analyzing tweets...\")\n",
        "        tweets_df = pd.read_csv(input_files[\"twitter\"])\n",
        "        sentiment_analysis = analyze_tweets(tweets_df, model=model_choice)\n",
        "\n",
        "        # Generate final report\n",
        "        print(\"\\nüìä Generating final report...\")\n",
        "        report = synthesize_report(whatsapp_analysis, screen_analysis, sentiment_analysis, model=model_choice)\n",
        "\n",
        "        # Display the report with nice formatting\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"üß† TEEN MENTAL HEALTH REPORT\".center(50))\n",
        "        print(\"=\"*50)\n",
        "        display(Markdown(report))\n",
        "        print(\"=\"*50)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n‚ùå Pipeline failed: {e}\")\n",
        "\n",
        "# Run the analysis\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Yxe-Le0k07SN",
        "outputId": "4b41384b-784a-494c-f776-1f4d059aa0f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.86.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.65)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.5)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Please upload your files:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4c5c12f6-5599-4a4f-8849-6e641c3b9301\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4c5c12f6-5599-4a4f-8849-6e641c3b9301\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TSA-teen age group, whatsapp_chat&screen_time_analysis.ipynb to TSA-teen age group, whatsapp_chat&screen_time_analysis (2).ipynb\n",
            "Uploaded files: ['TSA-teen age group, whatsapp_chat&screen_time_analysis (2).ipynb']\n",
            "\n",
            "üîë API Key Setup\n",
            "1. Get your OpenAI API key from: https://platform.openai.com/api-keys\n",
            "2. Get your DeepSeek API key from their website (if using DeepSeek)\n",
            "Enter your OpenAI API key (or press Enter to skip): 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\n",
            "Enter your DeepSeek API key (or press Enter to skip): \n",
            "‚úÖ OpenAI GPT initialized successfully\n",
            "‚ùå Could not identify these required files: screen_time, twitter\n",
            "Please ensure your uploaded files contain these keywords in their names:\n",
            "- whatsapp (or .zip) for WhatsApp chat\n",
            "- screen (or .csv) for screen time data\n",
            "- tweet (or .csv) for Twitter data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas python-dotenv mistral_ai openai tqdm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKCwdmdx3xcP",
        "outputId": "60b65715-dc8c-42e1-e188-03faa7e4d8ad"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.1.0)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement mistral_ai (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for mistral_ai\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from tqdm import tqdm\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema import HumanMessage\n",
        "import openai\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Initialize OpenAI client\n",
        "llm = openai.ChatCompletion()\n",
        "\n",
        "# WhatsApp Chat Extraction\n",
        "def extract_whatsapp_messages(zip_path):\n",
        "    # Placeholder for actual extraction logic\n",
        "    return [\"User1: Hello!\", \"User2: Hi there!\", \"User1: How are you?\"]\n",
        "\n",
        "# WhatsApp Chat Analysis\n",
        "def analyze_chat(messages, n=50):\n",
        "    recent = \"\\n\".join(messages[-n:])\n",
        "    prompt_template_str = \"\"\"\n",
        "    You are a futuristic AI therapist from 2030.\n",
        "\n",
        "    Analyze these WhatsApp messages:\n",
        "    - Emotional tone (stress, joy, anxiety)\n",
        "    - Mental clarity & decision style\n",
        "    - Mindset type: proactive, reactive, balanced\n",
        "\n",
        "    Recommend:\n",
        "    - 3 apps/habits to avoid\n",
        "    - 3 uplifting movies and songs\n",
        "    - 3 good daily mental health habits\n",
        "\n",
        "    Output ONLY in JSON format as:\n",
        "    {\"emotional_tone\": \"...\", \"clarity\": \"...\", \"mindset\": \"...\", \"avoid\": [...], \"recommend\": {\"movies\": [...], \"songs\": [...]}, \"habits\": [...] }\n",
        "    Chat:\n",
        "    {chat}\n",
        "    \"\"\"\n",
        "    prompt = PromptTemplate(input_variables=[\"chat\"], template=prompt_template_str)\n",
        "    formatted_prompt = prompt.format(chat=recent)\n",
        "\n",
        "    response = llm.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}]\n",
        "    )\n",
        "\n",
        "    text = response['choices'][0]['message']['content']\n",
        "    try:\n",
        "        return json.loads(text)\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"JSON parsing failed in chat analysis. Raw output:\\n\", text)\n",
        "        return text\n",
        "\n",
        "# Screen Time Analysis\n",
        "def load_screen_time(csv_path):\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path)\n",
        "        print(f\"Loaded screen time data: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to load screen time CSV: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def analyze_screen_time(df):\n",
        "    readable = df.to_string(index=False)\n",
        "    prompt_template_str = \"\"\"\n",
        "    You are a digital wellness AI.\n",
        "\n",
        "    Analyze this screen time data:\n",
        "    - Focus vs distraction\n",
        "    - Burnout, overuse, addiction\n",
        "    - Decision fatigue signs\n",
        "\n",
        "    Recommend:\n",
        "    - Mental clarity (0-100)\n",
        "    - Avoid apps\n",
        "    - 3 inspiring movies and calming songs\n",
        "    - 3 digital detox habits\n",
        "\n",
        "    Output ONLY in JSON format as:\n",
        "    {\"clarity_score\": 0, \"fatigue\": \"...\", \"avoid_apps\": [...], \"recommend\": {\"movies\": [...], \"songs\": [...]}, \"habits\": [...] }\n",
        "\n",
        "    Screen Time Data:\n",
        "    {data}\n",
        "    \"\"\"\n",
        "    prompt = PromptTemplate(input_variables=[\"data\"], template=prompt_template_str)\n",
        "    formatted_prompt = prompt.format(data=readable)\n",
        "\n",
        "    response = llm.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}]\n",
        "    )\n",
        "\n",
        "    text = response['choices'][0]['message']['content']\n",
        "    try:\n",
        "        data = json.loads(text)\n",
        "        if not isinstance(data, dict):\n",
        "            raise ValueError(\"Screen time JSON result is not a dictionary.\")\n",
        "        val = int(data.get(\"clarity_score\", 50))\n",
        "        data[\"clarity_score\"] = max(0, min(100, val))\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(\"Error processing screen time analysis:\", e)\n",
        "        return {\"clarity_score\": 50, \"fatigue\": \"Unknown\", \"avoid_apps\": [], \"recommend\": {\"movies\": [], \"songs\": []}, \"habits\": []}\n",
        "\n",
        "# Twitter Sentiment Analysis\n",
        "def analyze_tweets(df):\n",
        "    print(\"Columns in CSV:\", df.columns.tolist())\n",
        "    tweet_col = next((col for col in df.columns if col.strip().lower() in [\"tweet\", \"text\", \"message\", \"content\"]), None)\n",
        "    if not tweet_col:\n",
        "        string_cols = df.select_dtypes(include='object')\n",
        "        tweet_col = string_cols.apply(lambda c: c.str.len().mean()).idxmax()\n",
        "        print(f\"Auto-selected tweet column: '{tweet_col}'\")\n",
        "\n",
        "    def analyze_sentiment_llm(tweet):\n",
        "        prompt = f\"You are a sentiment expert. Classify the tweet as one word: Positive, Negative, or Neutral.\\n\\nTweet: \\\"{tweet}\\\"\\nSentiment:\"\n",
        "        try:\n",
        "            res = llm.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0.0\n",
        "            )\n",
        "            sentiment = res['choices'][0]['message']['content'].strip()\n",
        "            return sentiment if sentiment.lower() in [\"positive\", \"negative\", \"neutral\"] else \"Neutral\"\n",
        "        except Exception as e:\n",
        "            print(\"Error analyzing tweet:\", e)\n",
        "            return \"Error\"\n",
        "\n",
        "    tqdm.pandas()\n",
        "    df[\"sentiment\"] = df[tweet_col].progress_apply(analyze_sentiment_llm)\n",
        "    return df\n",
        "\n",
        "# Final Report Synthesis\n",
        "def synthesize_report(chat_json, screen_json, sentiment_df):\n",
        "    sentiment_counts = sentiment_df[\"sentiment\"].value_counts().to_dict()\n",
        "    sentiment_summary = f\"Sentiment counts: {sentiment_counts}\"\n",
        "\n",
        "    prompt_template_str = \"\"\"\n",
        "    You are a NeuroAI fusion advisor from the future.\n",
        "\n",
        "    Combine these:\n",
        "    1. WhatsApp analysis:\n",
        "    {chat_json}\n",
        "\n",
        "    2. Screen time report:\n",
        "    {screen_json}\n",
        "\n",
        "    3. Twitter sentiment:\n",
        "    {sentiments}\n",
        "\n",
        "    Summarize teen mental health:\n",
        "    - Mood and stress pattern\n",
        "    - Top 3 issues\n",
        "    - Mindfulness movie/song list\n",
        "    - Futuristic habit suggestions\n",
        "\n",
        "    Respond warmly and clearly.\n",
        "    \"\"\"\n",
        "    prompt = PromptTemplate(input_variables=[\"chat_json\", \"screen_json\", \"sentiments\"], template=prompt_template_str)\n",
        "    formatted_prompt = prompt.format(\n",
        "        chat_json=json.dumps(chat_json, indent=2) if isinstance(chat_json, dict) else str(chat_json),\n",
        "        screen_json=json.dumps(screen_json, indent=2) if isinstance(screen_json, dict) else str(screen_json),\n",
        "        sentiments=sentiment_summary\n",
        "    )\n",
        "\n",
        "    response = llm.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": formatted_prompt}]\n",
        "    )\n",
        "\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "# Main Pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    whatsapp_file = \"whatsapp_chat_analysis.zip\"\n",
        "    screen_time_file = \"screentime_analysis.csv\"\n",
        "    twitter_file = \"teen_tweets.csv\"\n",
        "\n",
        "    try:\n",
        "        chat_msgs = extract_whatsapp_messages(whatsapp_file)\n",
        "        chat_result = analyze_chat(chat_msgs) if chat_msgs else \"No usable messages.\"\n",
        "\n",
        "        df_screen = load_screen_time(screen_time_file)\n",
        "        screen_result = analyze_screen_time(df_screen) if not df_screen.empty else \"No screen time data.\"\n",
        "\n",
        "        df_tweets = pd.read_csv(twitter_file)\n",
        "        sentiment_df = analyze_tweets(df_tweets)\n",
        "\n",
        "        final_report = synthesize_report(chat_result, screen_result, sentiment_df)\n",
        "        print(\"\\nFinal Mental Health Summary:\\n\", final_report)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Pipeline error:\", e)\n",
        "\n",
        "\n",
        "\n",
        "def analyze_screen_time(df):\n",
        "    readable = df.to_string(index=False)\n",
        "\n",
        "    prompt_template_str = \"\"\"\n",
        "You are a digital wellness AI.\n",
        "\n",
        "Analyze this screen time data:\n",
        "- Focus vs distraction\n",
        "- Burnout, overuse, addiction\n",
        "- Decision fatigue signs\n",
        "\n",
        "Recommend:\n",
        "- Mental clarity (0-100)\n",
        "- Avoid apps\n",
        "- 3 inspiring movies and calming songs\n",
        "- 3 digital detox habits\n",
        "\n",
        "Output ONLY in JSON format as:\n",
        "{\"clarity_score\": 0, \"fatigue\": \"...\", \"avoid_apps\": [...], \"recommend\": {\"movies\": [...], \"songs\": [...]}, \"habits\": [...] }\n",
        "\n",
        "Screen Time Data:\n",
        "{data}\n",
        "\"\"\"\n",
        "    prompt = PromptTemplate(input_variables=[\"data\"], template=prompt_template_str)\n",
        "    formatted_prompt = prompt.format(data=readable)\n",
        "\n",
        "    response = llm([HumanMessage(content=formatted_prompt)])\n",
        "    text = response[0].content if isinstance(response, list) else getattr(response, \"content\", str(response))\n",
        "\n",
        "    try:\n",
        "        data = json.loads(text)\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"‚ö†Ô∏è JSON parsing failed in screen time analysis. Raw output:\\n\", text)\n",
        "        return {\"clarity_score\": 50, \"fatigue\": \"Unknown\", \"avoid_apps\": [], \"recommend\": {\"movies\": [], \"songs\": []}, \"habits\": []}\n",
        "\n",
        "    # ‚úÖ Validation & fallback handling\n",
        "    if not isinstance(data, dict):\n",
        "        print(\"‚ö†Ô∏è Screen time JSON result is not a dictionary.\")\n",
        "        return {\"clarity_score\": 50, \"fatigue\": \"Unknown\", \"avoid_apps\": [], \"recommend\": {\"movies\": [], \"songs\": []}, \"habits\": []}\n",
        "\n",
        "    # Clamp clarity score between 0‚Äì100\n",
        "    try:\n",
        "        val = int(data.get(\"clarity_score\", 50))\n",
        "        data[\"clarity_score\"] = max(0, min(100, val))\n",
        "    except Exception:\n",
        "        print(\"‚ö†Ô∏è Invalid clarity_score, setting default 50\")\n",
        "        data[\"clarity_score\"] = 50\n",
        "\n",
        "    return data\n",
        "print(f\"üß† Mood: {analysis['mood']} | üö© Issues: {', '.join(analysis['top_issues'])} | üé¨ Movies: {', '.join(analysis['recommended_movies'])} | üéµ Songs: {', '.join(analysis['recommended_songs'])} | üåø Habits: {', '.join(analysis['habits'])}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1dchuTkdthX",
        "outputId": "0e4dc836-fd5b-40e4-e8cf-f2e133d37fd0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline error: '\"emotional_tone\"'\n",
            "üß† Mood: Stressed and anxious with periods of joy | üö© Issues: Overuse of social media, Sleep deprivation, Lack of mental clarity | üé¨ Movies: Inside Out, The Pursuit of Happyness, Soul | üéµ Songs: Weightless - Marconi Union, Lovely Day - Bill Withers, Here Comes the Sun - The Beatles | üåø Habits: Daily journaling, 30-minute screen-free walk, Night-time digital detox routine\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r0ai178DzG7X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "mistral_api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
        "\n",
        "# Mock Mistral client for demonstration purposes\n",
        "class MistralClient:\n",
        "    def __init__(self, api_key):\n",
        "        self.api_key = api_key\n",
        "\n",
        "    def generate(self, model, prompt, max_tokens):\n",
        "        # Mock response\n",
        "        return json.dumps({\n",
        "            \"emotional_tone\": \"Neutral\",\n",
        "            \"clarity\": \"Clear\",\n",
        "            \"mindset\": \"Balanced\",\n",
        "            \"avoid\": [\"app1\", \"app2\", \"app3\"],\n",
        "            \"recommend\": {\"movies\": [\"Movie1\", \"Movie2\", \"Movie3\"], \"songs\": [\"Song1\", \"Song2\", \"Song3\"]},\n",
        "            \"habits\": [\"Habit1\", \"Habit2\", \"Habit3\"]\n",
        "        })\n",
        "\n",
        "mistral_client = MistralClient(api_key=mistral_api_key)\n",
        "\n",
        "# Example function to analyze chat using Mistral\n",
        "def analyze_chat_with_mistral(messages, n=50):\n",
        "    # Ensure that messages is a list and has elements\n",
        "    if not isinstance(messages, list) or not messages:\n",
        "        return {\"error\": \"Invalid messages input\"}\n",
        "\n",
        "    # Join the last n messages\n",
        "    recent = \"\\n\".join(messages[-n:])\n",
        "\n",
        "    # Define the prompt template\n",
        "    prompt_template_str = \"\"\"\n",
        "    You are a futuristic AI therapist from 2030.\n",
        "\n",
        "    Analyze these WhatsApp messages:\n",
        "    - Emotional tone (stress, joy, anxiety)\n",
        "    - Mental clarity & decision style\n",
        "    - Mindset type: proactive, reactive, balanced\n",
        "\n",
        "    Recommend:\n",
        "    - 3 apps/habits to avoid\n",
        "    - 3 uplifting movies and songs\n",
        "    - 3 good daily mental health habits\n",
        "\n",
        "    Output ONLY in JSON format as:\n",
        "    {{\"emotional_tone\": \"...\", \"clarity\": \"...\", \"mindset\": \"...\", \"avoid\": [...], \"recommend\": {{\"movies\": [...], \"songs\": [...]}}, \"habits\": [...] }}\n",
        "\n",
        "    Chat:\n",
        "    {chat}\n",
        "    \"\"\"\n",
        "\n",
        "    # Format the prompt string with the recent messages\n",
        "    prompt = prompt_template_str.format(chat=recent)\n",
        "\n",
        "    # Hypothetical call to Mistral's API\n",
        "    response = mistral_client.generate(\n",
        "        model=\"mistral-model\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=150\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        return json.loads(response)\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"JSON parsing failed in chat analysis. Raw output:\\n\", response)\n",
        "        return {\"error\": \"Failed to parse JSON response\"}\n",
        "\n",
        "\n",
        "# Example usage\n",
        "messages = [\"User1: Hello!\", \"User2: Hi there!\", \"User1: How are you?\"]\n",
        "analysis_result = analyze_chat_with_mistral(messages)\n",
        "print(analysis_result)\n",
        "\n",
        "# --- Screen Time Analysis ---\n",
        "def load_screen_time(csv_path):\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path)\n",
        "        print(f\"‚úÖ Loaded screen time data: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to load screen time CSV: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def analyze_screen_time(df):\n",
        "    readable = df.to_string(index=False)\n",
        "    prompt_template_str = \"\"\"\n",
        "You are a digital wellness AI.\n",
        "\n",
        "Analyze this screen time data:\n",
        "- Focus vs distraction\n",
        "- Burnout, overuse, addiction\n",
        "- Decision fatigue signs\n",
        "\n",
        "Recommend:\n",
        "- Mental clarity (0-100)\n",
        "- Avoid apps\n",
        "- 3 inspiring movies and calming songs\n",
        "- 3 digital detox habits\n",
        "\n",
        "Output ONLY in JSON format as:\n",
        "{\"clarity_score\": 0, \"fatigue\": \"...\", \"avoid_apps\": [...], \"recommend\": {\"movies\": [...], \"songs\": [...]}, \"habits\": [...] }\n",
        "\n",
        "Screen Time Data:\n",
        "{data}\n",
        "\"\"\"\n",
        "    formatted_prompt = prompt_template_str.format(data=readable)\n",
        "\n",
        "    # Mock response for demonstration\n",
        "    mock_response = json.dumps({\n",
        "        \"clarity_score\": 75,\n",
        "        \"fatigue\": \"Low\",\n",
        "        \"avoid_apps\": [\"App1\", \"App2\", \"App3\"],\n",
        "        \"recommend\": {\"movies\": [\"Movie1\", \"Movie2\", \"Movie3\"], \"songs\": [\"Song1\", \"Song2\", \"Song3\"]},\n",
        "        \"habits\": [\"Habit1\", \"Habit2\", \"Habit3\"]\n",
        "    })\n",
        "\n",
        "    try:\n",
        "        data = json.loads(mock_response)\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"‚ö†Ô∏è JSON parsing failed in screen time analysis. Raw output:\\n\", mock_response)\n",
        "        return {\"clarity_score\": 50, \"fatigue\": \"Unknown\", \"avoid_apps\": [], \"recommend\": {\"movies\": [], \"songs\": []}, \"habits\": []}\n",
        "\n",
        "    if not isinstance(data, dict):\n",
        "        print(\"‚ö†Ô∏è Screen time JSON result is not a dictionary.\")\n",
        "        return {\"clarity_score\": 50, \"fatigue\": \"Unknown\", \"avoid_apps\": [], \"recommend\": {\"movies\": [], \"songs\": []}, \"habits\": []}\n",
        "\n",
        "    try:\n",
        "        val = int(data.get(\"clarity_score\", 50))\n",
        "        data[\"clarity_score\"] = max(0, min(100, val))\n",
        "    except Exception:\n",
        "        print(\"‚ö†Ô∏è Invalid clarity_score, setting default 50\")\n",
        "        data[\"clarity_score\"] = 50\n",
        "\n",
        "    return data\n",
        "\n",
        "# --- Twitter Sentiment Analysis ---\n",
        "def analyze_tweets(df):\n",
        "    print(\"üîç Columns in CSV:\", df.columns.tolist())\n",
        "    tweet_col = None\n",
        "    for col in df.columns:\n",
        "        if col.strip().lower() in [\"tweet\", \"text\", \"message\", \"content\"]:\n",
        "            tweet_col = col\n",
        "            break\n",
        "    if not tweet_col:\n",
        "        string_cols = df.select_dtypes(include='object')\n",
        "        tweet_col = string_cols.apply(lambda c: c.str.len().mean()).idxmax()\n",
        "        print(f\"‚úÖ Auto-selected tweet column: '{tweet_col}'\")\n",
        "\n",
        "    def analyze_sentiment_llm(tweet):\n",
        "        prompt = f\"\"\"\n",
        "You are a sentiment expert. Classify the tweet as one word: Positive, Negative, or Neutral.\n",
        "\n",
        "Tweet: \"{tweet}\"\n",
        "Sentiment:\"\"\"\n",
        "        try:\n",
        "            # Mock response for demonstration\n",
        "            sentiment = \"Neutral\"\n",
        "            if sentiment.lower() not in [\"positive\", \"negative\", \"neutral\"]:\n",
        "                return \"Neutral\"\n",
        "            return sentiment\n",
        "        except Exception as e:\n",
        "            print(\"‚ö†Ô∏è Error analyzing tweet:\", e)\n",
        "            return \"Error\"\n",
        "\n",
        "    tqdm.pandas()\n",
        "    df[\"sentiment\"] = df[tweet_col].progress_apply(analyze_sentiment_llm)\n",
        "    return df\n",
        "\n",
        "# --- Final Report Synthesis ---\n",
        "def synthesize_report(chat_json, screen_json, sentiment_df):\n",
        "    sentiment_counts = sentiment_df[\"sentiment\"].value_counts().to_dict()\n",
        "    sentiment_summary = f\"Sentiment counts: {sentiment_counts}\"\n",
        "\n",
        "    prompt_template_str = \"\"\"\n",
        "You are a NeuroAI fusion advisor from the future.\n",
        "\n",
        "Combine these:\n",
        "1. WhatsApp analysis:\n",
        "{chat_json}\n",
        "\n",
        "2. Screen time report:\n",
        "{screen_json}\n",
        "\n",
        "3. Twitter sentiment:\n",
        "{sentiments}\n",
        "\n",
        "Summarize teen mental health:\n",
        "- Mood and stress pattern\n",
        "- Top 3 issues\n",
        "- Mindfulness movie/song list\n",
        "- Futuristic habit suggestions\n",
        "\n",
        "Respond warmly and clearly.\n",
        "\"\"\"\n",
        "    formatted_prompt = prompt_template_str.format(\n",
        "        chat_json=json.dumps(chat_json, indent=2) if isinstance(chat_json, dict) else str(chat_json),\n",
        "        screen_json=json.dumps(screen_json, indent=2) if isinstance(screen_json, dict) else str(screen_json),\n",
        "        sentiments=sentiment_summary\n",
        "    )\n",
        "\n",
        "    # Mock response for demonstration\n",
        "    mock_response = \"Final mental health summary based on the provided data.\"\n",
        "\n",
        "    return mock_response\n",
        "\n",
        "# --- MAIN PIPELINE ---\n",
        "if __name__ == \"__main__\":\n",
        "    whatsapp_file = \"whatsapp_chat_analysis.zip\"\n",
        "    screen_time_file = \"screentime_analysis.csv\"\n",
        "    twitter_file = \"teen_tweets.csv\"\n",
        "\n",
        "    try:\n",
        "        # Mock function for demonstration\n",
        "        def extract_whatsapp_messages(file_path):\n",
        "            return [\"User1: Hello!\", \"User2: Hi there!\", \"User1: How are you?\"]\n",
        "\n",
        "        # 1. WhatsApp\n",
        "        chat_msgs = extract_whatsapp_messages(whatsapp_file)\n",
        "        chat_result = analyze_chat_with_mistral(chat_msgs) if chat_msgs else \"No usable messages.\"\n",
        "\n",
        "        # 2. Screen Time\n",
        "        df_screen = load_screen_time(screen_time_file)\n",
        "        screen_result = analyze_screen_time(df_screen) if not df_screen.empty else \"No screen time data.\"\n",
        "\n",
        "        # 3. Twitter Sentiment\n",
        "        df_tweets = pd.DataFrame({\"tweet\": [\"I love this!\", \"Feeling great today\", \"Not sure about this\"]})\n",
        "        sentiment_df = analyze_tweets(df_tweets)\n",
        "\n",
        "        # 4. Final Mental Health Report\n",
        "        final_report = synthesize_report(chat_result, screen_result, sentiment_df)\n",
        "        print(\"\\nüß† Final Mental Health Summary:\\n\", final_report)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Pipeline Error:\", e)\n",
        "\n",
        "# --- INPUT JSON ---\n",
        "data = '''\n",
        "{\n",
        "  \"mood\": \"Stressed and anxious with periods of joy\",\n",
        "  \"top_issues\": [\"Overuse of social media\", \"Sleep deprivation\", \"Lack of mental clarity\"],\n",
        "  \"recommended_movies\": [\"Inside Out\", \"The Pursuit of Happyness\", \"Soul\"],\n",
        "  \"recommended_songs\": [\"Weightless - Marconi Union\", \"Lovely Day - Bill Withers\", \"Here Comes the Sun - The Beatles\"],\n",
        "  \"habits\": [\"Daily journaling\", \"30-minute screen-free walk\", \"Night-time digital detox routine\"]\n",
        "}\n",
        "'''\n",
        "\n",
        "# --- LOAD JSON INTO PYTHON DICTIONARY ---\n",
        "analysis = json.loads(data)\n",
        "\n",
        "# --- PRINT IN A CLEAN FORMAT ---\n",
        "print(\"\\nüß† Mood Summary:\")\n",
        "print(f\"  - Mood: {analysis['mood']}\")\n",
        "\n",
        "print(\"\\nüö© Top Issues Detected:\")\n",
        "for issue in analysis['top_issues']:\n",
        "    print(f\"  - {issue}\")\n",
        "\n",
        "print(\"\\nüé¨ Recommended Movies:\")\n",
        "for movie in analysis['recommended_movies']:\n",
        "    print(f\"  - {movie}\")\n",
        "\n",
        "print(\"\\nüéµ Recommended Songs:\")\n",
        "for song in analysis['recommended_songs']:\n",
        "    print(f\"  - {song}\")\n",
        "\n",
        "print(\"\\nüåø Suggested Mental Health Habits:\")\n",
        "for habit in analysis['habits']:\n",
        "    print(f\"  - {habit}\")\n",
        "\n",
        "print(f\"üß† Mood: {analysis['mood']} | üö© Issues: {', '.join(analysis['top_issues'])} | üé¨ Movies: {', '.join(analysis['recommended_movies'])} | üéµ Songs: {', '.join(analysis['recommended_songs'])} | üåø Habits: {', '.join(analysis['habits'])}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwOoN6CbzLNj",
        "outputId": "3c8294d1-7054-4548-e011-af0f2fa0f598"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'emotional_tone': 'Neutral', 'clarity': 'Clear', 'mindset': 'Balanced', 'avoid': ['app1', 'app2', 'app3'], 'recommend': {'movies': ['Movie1', 'Movie2', 'Movie3'], 'songs': ['Song1', 'Song2', 'Song3']}, 'habits': ['Habit1', 'Habit2', 'Habit3']}\n",
            "‚ùå Failed to load screen time CSV: [Errno 2] No such file or directory: 'screentime_analysis.csv'\n",
            "üîç Columns in CSV: ['tweet']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 5282.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üß† Final Mental Health Summary:\n",
            " Final mental health summary based on the provided data.\n",
            "\n",
            "üß† Mood Summary:\n",
            "  - Mood: Stressed and anxious with periods of joy\n",
            "\n",
            "üö© Top Issues Detected:\n",
            "  - Overuse of social media\n",
            "  - Sleep deprivation\n",
            "  - Lack of mental clarity\n",
            "\n",
            "üé¨ Recommended Movies:\n",
            "  - Inside Out\n",
            "  - The Pursuit of Happyness\n",
            "  - Soul\n",
            "\n",
            "üéµ Recommended Songs:\n",
            "  - Weightless - Marconi Union\n",
            "  - Lovely Day - Bill Withers\n",
            "  - Here Comes the Sun - The Beatles\n",
            "\n",
            "üåø Suggested Mental Health Habits:\n",
            "  - Daily journaling\n",
            "  - 30-minute screen-free walk\n",
            "  - Night-time digital detox routine\n",
            "üß† Mood: Stressed and anxious with periods of joy | üö© Issues: Overuse of social media, Sleep deprivation, Lack of mental clarity | üé¨ Movies: Inside Out, The Pursuit of Happyness, Soul | üéµ Songs: Weightless - Marconi Union, Lovely Day - Bill Withers, Here Comes the Sun - The Beatles | üåø Habits: Daily journaling, 30-minute screen-free walk, Night-time digital detox routine\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}